{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "     df,\n",
    "     test_size=0.2,\n",
    "     stratify=df[\"Survived\"],  \n",
    "     random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "val_df.to_csv(VAL_CSV, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16185982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "train = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "val  = pd.read_csv(VAL_CSV , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, val]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['IsAlone'] = 0\n",
    "train.loc[train['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50779787",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e407d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avg = train['Age'].mean()\n",
    "age_std = train['Age'].std()    \n",
    "age_null_count = train['Age'].isnull().sum()\n",
    "    \n",
    "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size = age_null_count)\n",
    "train['Age'][np.isnan(train['Age'])] = age_null_random_list\n",
    "train['Age'] = train['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train['Title'] = train['Name'].apply(get_title)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9342caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "le.fit(train['Title'])\n",
    "train['Title'] = le.transform(train['Title'])\n",
    "\n",
    "le.fit(train['Embarked'].values)\n",
    "train['Embarked'] = le.transform(train['Embarked'].values)\n",
    "\n",
    "le.fit(train['Fare'])\n",
    "train['Fare'] = le.transform(train['Fare'])\n",
    "\n",
    "le.fit(train['Age'])\n",
    "train['Age'] = le.transform(train['Age'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef85e67d",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e5403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        \n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "# Some method have been deprecated, so code should be changed \n",
    "log_entries = []\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] /= 10.0\n",
    "    log_entries.append([clf, acc_dict[clf]])\n",
    "\n",
    "log = pd.DataFrame(log_entries, columns=log_cols)\n",
    "# Ends here \n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x = 'Accuracy', y = 'Classifier', data = log, color = \"b\")\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f1831",
   "metadata": {},
   "source": [
    "### Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from os import getcwd\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings.constants import TRAIN_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "raw_train = pd.read_csv(TRAIN_CSV)\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "X_raw = raw_train[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_train.stroke\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "with open(getcwd() + '/models/RandForest.pickle', 'wb')as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d08b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from os import getcwd\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings. constants import VAL_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "raw_val = pd.read_csv(VAL_CSV)\n",
    "x_raw = raw_val[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(x_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_val.stroke\n",
    "\n",
    "loaded_model = pickle.load(open(getcwd() + '/models/RandForest.pickle', 'rb'))\n",
    "loaded_model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce56965",
   "metadata": {},
   "source": [
    "### API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import DataLoader, Estimator \n",
    "from settings. constants import TRAIN_CSV, VAL_CSV\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "    \n",
    "info = specifications['description']\n",
    "x_columns, y_column, metrics = info['X'], info['y'], info['metrics']\n",
    "\n",
    "train_set = pd.read_csv(TRAIN_CSV, header=0)\n",
    "val_set = pd.read_csv(VAL_CSV, header=0)\n",
    "\n",
    "train_x, train_y = train_set[x_columns], train_set[y_column]\n",
    "val_x, val_y = val_set[x_columns], val_set[y_column]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(val_x)\n",
    "val_processed = loader.load_data()\n",
    "print('data: ', val_processed[:10])\n",
    "\n",
    "req_data = {'data': json.dumps(val_x.to_dict())}\n",
    "\n",
    "# To test localhost is used\n",
    "response = requests.get('http://127.0.0.1:8000/predict', data=req_data)\n",
    "api_predict = response.json()['prediction']\n",
    "print('predict: ', api_predict[:10])\n",
    "\n",
    "api_score = eval(metrics)(val_y, api_predict)\n",
    "print('accuracy: ', api_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a07bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3edc34",
   "metadata": {},
   "source": [
    "# Other dataset preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0c7fb",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good idea to split all the BMIs in 4 ranges:\n",
    "# -underw\n",
    "# -normal\n",
    "# -overweight\n",
    "# -obesity\n",
    "# -nans - to fill with obesity\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df['bmi_rr'] = -1\n",
    "df.loc[(18.5 >= df['bmi']), 'bmi_rr'] = 0\n",
    "df.loc[(18.5 < df['bmi']) & (25 >= df['bmi']), 'bmi_rr'] = 1\n",
    "df.loc[(25 < df['bmi']) & (30 >= df['bmi']), 'bmi_rr'] = 2\n",
    "df.loc[(30 < df['bmi']), 'bmi_rr'] = 3\n",
    "df.loc[df['bmi_rr'] == -1, 'bmi_rr'] = 3\n",
    "\n",
    "y = df[[\"bmi_rr\", \"stroke\"]].groupby(['bmi_rr'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's treat BMI differently\n",
    "# -nans - to fill with median\n",
    "# It seems that it's a bad idea, since it makes people with overweight \n",
    "# to have bigger chances of stroke than obesed people \n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df.loc[df['bmi'].isna(), 'bmi'] = df['bmi'].median()\n",
    "df['bmi_rr'] = -1\n",
    "df.loc[(18.5 >= df['bmi']), 'bmi_rr'] = 0\n",
    "df.loc[(18.5 < df['bmi']) & (25 >= df['bmi']), 'bmi_rr'] = 1\n",
    "df.loc[(25 < df['bmi']) & (30 >= df['bmi']), 'bmi_rr'] = 2\n",
    "df.loc[(30 < df['bmi']), 'bmi_rr'] = 3\n",
    "\n",
    "y = df[[\"bmi_rr\", \"stroke\"]].groupby(['bmi_rr'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way - to fill NANs in BMI by categories, for instance - gender and age\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df['bmi'] = df.groupby(['age', 'gender'])['bmi'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df['bmi_rr'] = -1\n",
    "df.loc[(18.5 >= df['bmi']), 'bmi_rr'] = 0\n",
    "df.loc[(18.5 < df['bmi']) & (25 >= df['bmi']), 'bmi_rr'] = 1\n",
    "df.loc[(25 < df['bmi']) & (30 >= df['bmi']), 'bmi_rr'] = 2\n",
    "df.loc[(30 < df['bmi']), 'bmi_rr'] = 3\n",
    "\n",
    "y = df[[\"bmi_rr\", \"stroke\"]].groupby(['bmi_rr'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c56317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both genders tend to not fill BMI equally often\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df[df['bmi'].isna()].groupby('gender').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f7208",
   "metadata": {},
   "source": [
    "### Glucose level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15443d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that there is a threshold value that corresponded with higher level of stroke\n",
    "\n",
    "n = int(2 * 5000 ** 0.3) + 1\n",
    "n = 8\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['avg_glucose_level_r'] = -1.0\n",
    "df['avg_glucose_level_r'] = pd.qcut(df['avg_glucose_level'], int(n))\n",
    "\n",
    "y = df[[\"avg_glucose_level_r\", \"stroke\"]].groupby(['avg_glucose_level_r'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['avg_glucose_level_r'] = -1\n",
    "df.loc[df['avg_glucose_level'] < 150, 'avg_glucose_level_r'] = 0\n",
    "df.loc[df['avg_glucose_level'] >= 150, 'avg_glucose_level_r'] = 1\n",
    "\n",
    "y = df[[\"avg_glucose_level_r\", \"stroke\"]].groupby(['avg_glucose_level_r'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bc75d",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a strong correlation between the age in decades and stroke chances \n",
    "\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['age_r'] = -1\n",
    "df['age_r'] = df['age'] // 10\n",
    "y = df[[\"age_r\", \"stroke\"]].groupby(['age_r'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a9f02",
   "metadata": {},
   "source": [
    "### Hypertension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c74128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a strong correlation between the hypertension and stroke chances \n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"hypertension\", \"stroke\"]].groupby(['hypertension'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b9043",
   "metadata": {},
   "source": [
    "### Heart disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86916e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a strong correlation between the heart_disease and stroke chances \n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"heart_disease\", \"stroke\"]].groupby(['heart_disease'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ad5fb",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No correlation between stroke and gender\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"gender\", \"stroke\"]].groupby(['gender'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09136b1b",
   "metadata": {},
   "source": [
    "### Mariage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No correlation between stroke and gender\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"ever_married\", \"stroke\"]].groupby(['ever_married'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c8c2a",
   "metadata": {},
   "source": [
    "### Smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is correlation for smokers and former smokers\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"smoking_status\", \"stroke\"]].groupby(['smoking_status'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9537059",
   "metadata": {},
   "source": [
    "### Residence type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is modest correlation for res type\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"Residence_type\", \"stroke\"]].groupby(['Residence_type'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23042643",
   "metadata": {},
   "source": [
    "### Residence + glucose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['Residence_type'] = df['Residence_type'].replace({'Rural': 1, 'Urban': 2})\n",
    "\n",
    "df['res_times_gluc'] = df['Residence_type'] * df['avg_glucose_level']\n",
    "df[['res_times_gluc', 'stroke']].groupby('stroke').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e152bb7",
   "metadata": {},
   "source": [
    "### hypertension + heart disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smoking_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f2aba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['ever_married'] = df['ever_married'].replace({'Yes': 1, 'No': 2})\n",
    "df['smoking_status'] = df['smoking_status'].replace({'never smoked': 1, 'Unknown': 2, 'formerly smoked':3, 'smokes': 4})\n",
    "\n",
    "df['age_r'] = -1\n",
    "df['age_r'] = df['age'] // 10\n",
    "\n",
    "df['hh'] = df['hypertension'] + df['heart_disease']\n",
    "df[['hh', 'stroke']].groupby('hh').mean()\n",
    "\n",
    "y = df[[\"hh\", \"stroke\"]].groupby(['hh'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba485bf9",
   "metadata": {},
   "source": [
    "# Final feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23173ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "# Age in decades\n",
    "df['age_in_decades'] = 0.1 * df['age']\n",
    "df['age_in_decades'] = df['age_in_decades'].astype(int)\n",
    "\n",
    "# BMI NANs\n",
    "df.loc[df['bmi'].isna(), 'bmi'] = df['bmi'].median()\n",
    "\n",
    "# BMI\n",
    "df['bmi'] = pd.cut(\n",
    "    df['bmi'],\n",
    "    bins=[-float('inf'), 18.5, 25, 30, float('inf')],\n",
    "    labels=[0, 1, 2, 3],\n",
    "    right=True\n",
    ").astype(int)\n",
    "\n",
    "# Glucose level\n",
    "df['avg_glucose_level'] = pd.qcut(df['avg_glucose_level'], 8)\n",
    "\n",
    "# heart_disease_total\n",
    "df['heart_disease_total'] = df['hypertension'] + df['heart_disease']\n",
    "\n",
    "# Droping non necessary columns\n",
    "drop_elements = ['id', 'age', 'Residence_type', 'hypertension', 'heart_disease', 'gender']\n",
    "df = df.drop(drop_elements, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00644e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(df['ever_married'])\n",
    "df['ever_married'] = le.transform(df['ever_married'])\n",
    "\n",
    "le.fit(df['work_type'])\n",
    "df['work_type'] = le.transform(df['work_type'])\n",
    "\n",
    "le.fit(df['smoking_status'])\n",
    "df['smoking_status'] = le.transform(df['smoking_status'])\n",
    "\n",
    "le.fit(df['avg_glucose_level'])\n",
    "df['avg_glucose_level'] = le.transform(df['avg_glucose_level'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbde1d4",
   "metadata": {},
   "source": [
    "### Some skidadle skidoodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ever_married'] = df['ever_married'].replace({'Yes': 1, 'No': 2})\n",
    "df['smoking_status'] = df['smoking_status'].replace({'never smoked': 1, 'Unknown': 2, 'formerly smoked':3, 'smokes': 4})\n",
    "df['work_type'] = df['work_type'].replace({'Never_worked': 0, 'children': 1, 'Govt_job': 2,\n",
    "                                                     'Private': 3, 'Self-employed': 4})\n",
    "\n",
    "df['social_factors'] = df['ever_married'] + df['smoking_status'] + df['work_type']\n",
    "df[['social_factors', 'stroke']].groupby('social_factors').mean()\n",
    "\n",
    "y = df[[\"social_factors\", \"stroke\"]].groupby(['social_factors'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "y = y.stroke.to_list()\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1682ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "     df,\n",
    "     test_size=0.2,\n",
    "     stratify=df[[\"age\"]],  \n",
    "     random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "val_df.to_csv(VAL_CSV, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbdb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    print(train_df[col].unique())\n",
    "    print(val_df[col].unique())\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a92be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
