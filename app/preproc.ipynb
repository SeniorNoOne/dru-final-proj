{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77027f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "     df,\n",
    "     test_size=0.2,\n",
    "     stratify=df[\"Survived\"],  \n",
    "     random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "val_df.to_csv(VAL_CSV, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82368e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "train = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "val  = pd.read_csv(VAL_CSV , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, val]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300981e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1204f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5334e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b930486",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['IsAlone'] = 0\n",
    "train.loc[train['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24358a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee88c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68dbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avg = train['Age'].mean()\n",
    "age_std = train['Age'].std()    \n",
    "age_null_count = train['Age'].isnull().sum()\n",
    "    \n",
    "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size = age_null_count)\n",
    "train['Age'][np.isnan(train['Age'])] = age_null_random_list\n",
    "train['Age'] = train['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train['Title'] = train['Name'].apply(get_title)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7dbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "le.fit(train['Title'])\n",
    "train['Title'] = le.transform(train['Title'])\n",
    "\n",
    "le.fit(train['Embarked'].values)\n",
    "train['Embarked'] = le.transform(train['Embarked'].values)\n",
    "\n",
    "le.fit(train['Fare'])\n",
    "train['Fare'] = le.transform(train['Fare'])\n",
    "\n",
    "le.fit(train['Age'])\n",
    "train['Age'] = le.transform(train['Age'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import DataLoader\n",
    "\n",
    "X_raw = train.drop(\"Survived\", axis=1)\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        \n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "# Some method have been deprecated, so code should be changed \n",
    "log_entries = []\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] /= 10.0\n",
    "    log_entries.append([clf, acc_dict[clf]])\n",
    "\n",
    "log = pd.DataFrame(log_entries, columns=log_cols)\n",
    "# Ends here \n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x = 'Accuracy', y = 'Classifier', data = log, color = \"b\")\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from os import getcwd\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings.constants import TRAIN_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "raw_train = pd.read_csv(TRAIN_CSV)\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "X_raw = raw_train[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_train.Survived\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "with open(getcwd() + '/models/SVC.pickle', 'wb')as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings. constants import VAL_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "raw_val = pd.read_csv(VAL_CSV)\n",
    "x_raw = raw_val[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(x_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_val.Survived\n",
    "\n",
    "loaded_model = pickle.load(open(getcwd() + '/models/SVC.pickle', 'rb'))\n",
    "loaded_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40213341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:     Pclass  Sex  Age  Fare  Embarked  IsAlone  Title\n",
      "0       3    1    1     2         2        0      2\n",
      "1       3    1    3     2         2        0      2\n",
      "2       3    1    1     0         0        1      2\n",
      "3       3    1    2     1         2        0      2\n",
      "4       3    0    1     2         1        0      1\n",
      "5       3    0    2     2         2        0      3\n",
      "6       2    0    2     1         2        1      1\n",
      "7       1    1    3     2         2        1      4\n",
      "8       1    1    3     3         0        0      2\n",
      "9       2    1    2     2         2        0      2\n",
      "predict:  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "accuracy:  0.8044692737430168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python\\dru-final-proj\\app\\utils\\dataloader.py:45: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.dataset['Age'][np.isnan(self.dataset['Age'])] = age_null_random_list\n",
      "F:\\Python\\dru-final-proj\\app\\utils\\dataloader.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataset['Age'][np.isnan(self.dataset['Age'])] = age_null_random_list\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import DataLoader, Estimator \n",
    "from settings. constants import TRAIN_CSV, VAL_CSV\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "    \n",
    "info = specifications['description']\n",
    "x_columns, y_column, metrics = info['X'], info['y'], info['metrics']\n",
    "\n",
    "train_set = pd.read_csv(TRAIN_CSV, header=0)\n",
    "val_set = pd.read_csv(VAL_CSV, header=0)\n",
    "\n",
    "train_x, train_y = train_set[x_columns], train_set[y_column]\n",
    "val_x, val_y = val_set[x_columns], val_set[y_column]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(val_x)\n",
    "val_processed = loader.load_data()\n",
    "print('data: ', val_processed[:10])\n",
    "\n",
    "req_data = {'data': json.dumps(val_x.to_dict())}\n",
    "\n",
    "# To test localhost is used\n",
    "response = requests.get('http://127.0.0.1:8000/predict', data=req_data)\n",
    "api_predict = response.json()['prediction']\n",
    "print('predict: ', api_predict[:10])\n",
    "\n",
    "api_score = eval(metrics)(val_y, api_predict)\n",
    "print('accuracy: ', api_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f40bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
