{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "     df,\n",
    "     test_size=0.2,\n",
    "     stratify=df[\"Survived\"],  \n",
    "     random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "val_df.to_csv(VAL_CSV, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617eddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "train = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "val  = pd.read_csv(VAL_CSV , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, val]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce45dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553af1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ebd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda86298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['IsAlone'] = 0\n",
    "train.loc[train['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avg = train['Age'].mean()\n",
    "age_std = train['Age'].std()    \n",
    "age_null_count = train['Age'].isnull().sum()\n",
    "    \n",
    "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size = age_null_count)\n",
    "train['Age'][np.isnan(train['Age'])] = age_null_random_list\n",
    "train['Age'] = train['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train['Title'] = train['Name'].apply(get_title)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa669d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "le.fit(train['Title'])\n",
    "train['Title'] = le.transform(train['Title'])\n",
    "\n",
    "le.fit(train['Embarked'].values)\n",
    "train['Embarked'] = le.transform(train['Embarked'].values)\n",
    "\n",
    "le.fit(train['Fare'])\n",
    "train['Fare'] = le.transform(train['Fare'])\n",
    "\n",
    "le.fit(train['Age'])\n",
    "train['Age'] = le.transform(train['Age'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import DataLoader\n",
    "\n",
    "X_raw = train.drop(\"Survived\", axis=1)\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c351ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        \n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "# Some method have been deprecated, so code should be changed \n",
    "log_entries = []\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] /= 10.0\n",
    "    log_entries.append([clf, acc_dict[clf]])\n",
    "\n",
    "log = pd.DataFrame(log_entries, columns=log_cols)\n",
    "# Ends here \n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x = 'Accuracy', y = 'Classifier', data = log, color = \"b\")\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from os import getcwd\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings.constants import TRAIN_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "raw_train = pd.read_csv(TRAIN_CSV)\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "X_raw = raw_train[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_train.Survived\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "with open(getcwd() + '/models/SVC.pickle', 'wb')as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings. constants import VAL_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "raw_val = pd.read_csv(VAL_CSV)\n",
    "x_raw = raw_val[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(x_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_val.Survived\n",
    "\n",
    "loaded_model = pickle.load(open(getcwd() + '/models/SVC.pickle', 'rb'))\n",
    "loaded_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import DataLoader, Estimator \n",
    "from settings. constants import TRAIN_CSV, VAL_CSV\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "    \n",
    "info = specifications['description']\n",
    "x_columns, y_column, metrics = info['X'], info['y'], info['metrics']\n",
    "\n",
    "train_set = pd.read_csv(TRAIN_CSV, header=0)\n",
    "val_set = pd.read_csv(VAL_CSV, header=0)\n",
    "\n",
    "train_x, train_y = train_set[x_columns], train_set[y_column]\n",
    "val_x, val_y = val_set[x_columns], val_set[y_column]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(val_x)\n",
    "val_processed = loader.load_data()\n",
    "print('data: ', val_processed[:10])\n",
    "\n",
    "req_data = {'data': json.dumps(val_x.to_dict())}\n",
    "\n",
    "# To test localhost is used\n",
    "response = requests.get('http://127.0.0.1:8000/predict', data=req_data)\n",
    "api_predict = response.json()['prediction']\n",
    "print('predict: ', api_predict[:10])\n",
    "\n",
    "api_score = eval(metrics)(val_y, api_predict)\n",
    "print('accuracy: ', api_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2056a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
