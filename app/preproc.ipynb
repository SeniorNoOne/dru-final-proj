{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94161868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "     df,\n",
    "     test_size=0.2,\n",
    "     stratify=df[\"Survived\"],  \n",
    "     random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "val_df.to_csv(VAL_CSV, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "\n",
    "from settings.constants import TRAIN_CSV, VAL_CSV \n",
    "\n",
    "train = pd.read_csv(TRAIN_CSV, header = 0, dtype={'Age': np.float64})\n",
    "val  = pd.read_csv(VAL_CSV , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, val]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ba08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425168a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['IsAlone'] = 0\n",
    "train.loc[train['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363843c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avg = train['Age'].mean()\n",
    "age_std = train['Age'].std()    \n",
    "age_null_count = train['Age'].isnull().sum()\n",
    "    \n",
    "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size = age_null_count)\n",
    "train['Age'][np.isnan(train['Age'])] = age_null_random_list\n",
    "train['Age'] = train['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train['Title'] = train['Name'].apply(get_title)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85319e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80142d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "le.fit(train['Title'])\n",
    "train['Title'] = le.transform(train['Title'])\n",
    "\n",
    "le.fit(train['Embarked'].values)\n",
    "train['Embarked'] = le.transform(train['Embarked'].values)\n",
    "\n",
    "le.fit(train['Fare'])\n",
    "train['Fare'] = le.transform(train['Fare'])\n",
    "\n",
    "le.fit(train['Age'])\n",
    "train['Age'] = le.transform(train['Age'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train['Sex'])\n",
    "train['Sex'] = le.transform(train['Sex'])\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf40830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import DataLoader\n",
    "\n",
    "X_raw = train.drop(\"Survived\", axis=1)\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef278008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        \n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "# Some method have been deprecated, so code should be changed \n",
    "log_entries = []\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] /= 10.0\n",
    "    log_entries.append([clf, acc_dict[clf]])\n",
    "\n",
    "log = pd.DataFrame(log_entries, columns=log_cols)\n",
    "# Ends here \n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x = 'Accuracy', y = 'Classifier', data = log, color = \"b\")\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from os import getcwd\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings.constants import TRAIN_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "raw_train = pd.read_csv(TRAIN_CSV)\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "X_raw = raw_train[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(X_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_train.Survived\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "with open(getcwd() + '/models/SVC.pickle', 'wb')as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings. constants import VAL_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "x_columns = specifications['description']['X']\n",
    "y_column = specifications['description']['y']\n",
    "\n",
    "raw_val = pd.read_csv(VAL_CSV)\n",
    "x_raw = raw_val[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(x_raw)\n",
    "X = loader.load_data()\n",
    "y = raw_val.Survived\n",
    "\n",
    "loaded_model = pickle.load(open(getcwd() + '/models/SVC.pickle', 'rb'))\n",
    "loaded_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import DataLoader, Estimator \n",
    "from settings. constants import TRAIN_CSV, VAL_CSV\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "    \n",
    "info = specifications['description']\n",
    "x_columns, y_column, metrics = info['X'], info['y'], info['metrics']\n",
    "\n",
    "train_set = pd.read_csv(TRAIN_CSV, header=0)\n",
    "val_set = pd.read_csv(VAL_CSV, header=0)\n",
    "\n",
    "train_x, train_y = train_set[x_columns], train_set[y_column]\n",
    "val_x, val_y = val_set[x_columns], val_set[y_column]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(val_x)\n",
    "val_processed = loader.load_data()\n",
    "print('data: ', val_processed[:10])\n",
    "\n",
    "req_data = {'data': json.dumps(val_x.to_dict())}\n",
    "\n",
    "# To test localhost is used\n",
    "response = requests.get('http://127.0.0.1:8000/predict', data=req_data)\n",
    "api_predict = response.json()['prediction']\n",
    "print('predict: ', api_predict[:10])\n",
    "\n",
    "api_score = eval(metrics)(val_y, api_predict)\n",
    "print('accuracy: ', api_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee772a4c",
   "metadata": {},
   "source": [
    "# Other dataset preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51e1f2",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good idea to split all the BMIs in 4 ranges:\n",
    "# -underw\n",
    "# -normal\n",
    "# -overweight\n",
    "# -obesity\n",
    "# -nans - to fill with obesity\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df['bmi_rr'] = -1\n",
    "df.loc[(18.5 >= df['bmi']), 'bmi_rr'] = 0\n",
    "df.loc[(18.5 < df['bmi']) & (25 >= df['bmi']), 'bmi_rr'] = 1\n",
    "df.loc[(25 < df['bmi']) & (30 >= df['bmi']), 'bmi_rr'] = 2\n",
    "df.loc[(30 < df['bmi']), 'bmi_rr'] = 3\n",
    "df.loc[df['bmi_rr'] == -1, 'bmi_rr'] = 3\n",
    "\n",
    "y = df[[\"bmi_rr\", \"stroke\"]].groupby(['bmi_rr'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44fc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's treat BMI differently\n",
    "# -nans - to fill with median\n",
    "# It seems that it's a bad idea, since it makes people with overweight \n",
    "# to have bigger chances of stroke than obesed people \n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df.loc[df['bmi'].isna(), 'bmi'] = df['bmi'].median()\n",
    "df['bmi_rr'] = -1\n",
    "df.loc[(18.5 >= df['bmi']), 'bmi_rr'] = 0\n",
    "df.loc[(18.5 < df['bmi']) & (25 >= df['bmi']), 'bmi_rr'] = 1\n",
    "df.loc[(25 < df['bmi']) & (30 >= df['bmi']), 'bmi_rr'] = 2\n",
    "df.loc[(30 < df['bmi']), 'bmi_rr'] = 3\n",
    "\n",
    "y = df[[\"bmi_rr\", \"stroke\"]].groupby(['bmi_rr'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1abb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way - to fill NANs in BMI by categories, for instance - gender and age\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df['bmi'] = df.groupby(['age', 'gender'])['bmi'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df['bmi_rr'] = -1\n",
    "df.loc[(18.5 >= df['bmi']), 'bmi_rr'] = 0\n",
    "df.loc[(18.5 < df['bmi']) & (25 >= df['bmi']), 'bmi_rr'] = 1\n",
    "df.loc[(25 < df['bmi']) & (30 >= df['bmi']), 'bmi_rr'] = 2\n",
    "df.loc[(30 < df['bmi']), 'bmi_rr'] = 3\n",
    "\n",
    "y = df[[\"bmi_rr\", \"stroke\"]].groupby(['bmi_rr'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both genders tend to not fill BMI equally often\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "df[df['bmi'].isna()].groupby('gender').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce6375",
   "metadata": {},
   "source": [
    "### Glucose level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c88626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that there is a threshold value that corresponded with higher level of stroke\n",
    "\n",
    "n = int(2 * 5000 ** 0.3) + 1\n",
    "n = 8\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['avg_glucose_level_r'] = -1.0\n",
    "df['avg_glucose_level_r'] = pd.qcut(df['avg_glucose_level'], int(n))\n",
    "\n",
    "y = df[[\"avg_glucose_level_r\", \"stroke\"]].groupby(['avg_glucose_level_r'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9357702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['avg_glucose_level_r'] = -1\n",
    "df.loc[df['avg_glucose_level'] < 150, 'avg_glucose_level_r'] = 0\n",
    "df.loc[df['avg_glucose_level'] >= 150, 'avg_glucose_level_r'] = 1\n",
    "\n",
    "y = df[[\"avg_glucose_level_r\", \"stroke\"]].groupby(['avg_glucose_level_r'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16f3b4",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc874776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a strong correlation between the age in decades and stroke chances \n",
    "\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['age_r'] = -1\n",
    "df['age_r'] = df['age'] // 10\n",
    "y = df[[\"age_r\", \"stroke\"]].groupby(['age_r'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0f5e9",
   "metadata": {},
   "source": [
    "### Hypertension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c08570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a strong correlation between the hypertension and stroke chances \n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"hypertension\", \"stroke\"]].groupby(['hypertension'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8c0cc",
   "metadata": {},
   "source": [
    "### Heart disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b131708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a strong correlation between the heart_disease and stroke chances \n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"heart_disease\", \"stroke\"]].groupby(['heart_disease'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412e669",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No correlation between stroke and gender\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"gender\", \"stroke\"]].groupby(['gender'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98af855",
   "metadata": {},
   "source": [
    "### Mariage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No correlation between stroke and gender\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"ever_married\", \"stroke\"]].groupby(['ever_married'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e060bda",
   "metadata": {},
   "source": [
    "### Smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is correlation for smokers and former smokers\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"smoking_status\", \"stroke\"]].groupby(['smoking_status'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd4ab6",
   "metadata": {},
   "source": [
    "### Residence type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is modest correlation for res type\n",
    "\n",
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "y = df[[\"Residence_type\", \"stroke\"]].groupby(['Residence_type'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283cbe8a",
   "metadata": {},
   "source": [
    "### Residence + glucose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afaee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['Residence_type'] = df['Residence_type'].replace({'Rural': 1, 'Urban': 2})\n",
    "\n",
    "df['res_times_gluc'] = df['Residence_type'] * df['avg_glucose_level'] ** 2\n",
    "df[['res_times_gluc', 'stroke']].groupby('stroke').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b09493",
   "metadata": {},
   "source": [
    "### hypertension + heart disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a3301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/healthcare-dataset-stroke-data.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "df['ever_married'] = df['ever_married'].replace({'Yes': 1, 'No': 2})\n",
    "\n",
    "df['age_r'] = -1\n",
    "df['age_r'] = df['age'] // 10\n",
    "\n",
    "df['hh'] = df['hypertension'] * df['heart_disease']\n",
    "df[['hh', 'stroke']].groupby('hh').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"hh\", \"stroke\"]].groupby(['hh'], as_index = False).mean()\n",
    "x = range(len(y.index))\n",
    "\n",
    "plt.scatter(x, y.stroke.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24feb67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
